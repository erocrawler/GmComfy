#!/usr/bin/env python3
"""
Auto-download script for ComfyUI models, LoRAs, VAEs, and text encoders.
This script downloads all necessary files for the WAN image-to-video workflow.
"""

import os
import sys
import requests
from pathlib import Path
from typing import Dict, List
from tqdm import tqdm
import argparse


# Model configurations
MODELS = {
    # Text Encoder / CLIP
    "clip": {
        "umt5_xxl_fp8_e4m3fn_scaled.safetensors": {
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "path": "models/clip",
            "size_gb": 6.7,
        },
        "": {
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp16.safetensors",
            "path": "models/clip",
            "size_gb": 11.4,
        }
    },

    
    
    # VAE
    "vae": {
        "wan_2.1_vae.safetensors": {
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
            "path": "models/vae",
            "size_gb": 0.3,
        }
    },
    
    # Diffusion Models
    "diffusion_models": {
        "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors": {
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
            "path": "models/diffusion_models",
            "size_gb": 7.3,
        },
        "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors": {
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
            "path": "models/diffusion_models",
            "size_gb": 7.3,
        }
    },
    
    # UNet models (GGUF quantized)
    "unet": {
        "wan2.2_i2v_high_noise_14B_Q8_0.gguf": {
            "url": "https://huggingface.co/bullerwins/Wan2.2-I2V-A14B-GGUF/resolve/main/wan2.2_i2v_high_noise_14B_Q8_0.gguf",
            "path": "models/unet",
            "size_gb": 14.5,
        },
        "wan2.2_i2v_low_noise_14B_Q8_0.gguf": {
            "url": "https://huggingface.co/bullerwins/Wan2.2-I2V-A14B-GGUF/resolve/main/wan2.2_i2v_low_noise_14B_Q8_0.gguf",
            "path": "models/unet",
            "size_gb": 14.5,
        },
        # CivitAI GGUF models
        "DasiwaWAN22I2V14BTastysinV8_q8High.gguf": {
            "url": "https://civitai.com/api/download/models/2466604",
            "path": "models/unet",
            "size_gb": 14.5,
        },
        "DasiwaWAN22I2V14BTastysinV8_q8Low.gguf": {
            "url": "https://civitai.com/api/download/models/2466822",
            "path": "models/unet",
            "size_gb": 14.5,
        }
    },
    
    # LoRAs
    "loras": {
        "wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors": {
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors",
            "path": "models/loras",
            "size_gb": 0.5,
        },
        "wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors": {
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors",
            "path": "models/loras",
            "size_gb": 0.5,
        },
        "wan22-video10-arcshot-16-sel-7-high.safetensors": {
            "url": "https://huggingface.co/UnifiedHorusRA/ArcShot-Wan2.2_2.1-I2V-A14B/resolve/main/wan22-video10-arcshot-16-sel-7-high.safetensors",
            "path": "models/loras",
            "size_gb": 0.3,
        },
        "DR34ML4Y_I2V_14B_HIGH.safetensors": {
            "url": "https://huggingface.co/wiikoo/WAN-LORA/resolve/main/wan2.2/DR34ML4Y_I2V_14B_HIGH.safetensors",
            "path": "models/loras",
            "size_gb": 0.3,
        },
        "DR34ML4Y_I2V_14B_LOW.safetensors": {
            "url": "https://huggingface.co/wiikoo/WAN-LORA/resolve/main/wan2.2/DR34ML4Y_I2V_14B_LOW.safetensors",
            "path": "models/loras",
            "size_gb": 0.3,
        },
        "NSFW-22-H-e8.safetensors": {
            "url": "https://huggingface.co/wiikoo/WAN-LORA/resolve/main/wan2.2/NSFW-22-H-e8.safetensors",
            "path": "models/loras",
            "size_gb": 0.1,
        },
        "NSFW-22-L-e8.safetensors": {
            "url": "https://huggingface.co/wiikoo/WAN-LORA/resolve/main/wan2.2/NSFW-22-L-e8.safetensors",
            "path": "models/loras",
            "size_gb": 0.1,
        },
        "cumshot_wan22_high.safetensors": {
            "url": "https://huggingface.co/seraphimzz/wan22/resolve/main/cumshot_wan22_high.safetensors",
            "path": "models/loras",
            "size_gb": 0.3,
        },
        "cumshot_wan22_low.safetensors": {
            "url": "https://huggingface.co/seraphimzz/wan22/resolve/main/cumshot_wan22_low.safetensors",
            "path": "models/loras",
            "size_gb": 0.3,
        }
    }
}


def download_file(url: str, dest_path: Path, desc: str = None, civitai_token: str = None) -> bool:
    """
    Download a file with progress bar.
    
    Args:
        url: URL to download from
        dest_path: Destination file path
        desc: Description for progress bar
        civitai_token: CivitAI API token for authenticated downloads
        
    Returns:
        True if successful, False otherwise
    """
    try:
        # Check if file already exists
        if dest_path.exists():
            print(f"âœ“ {dest_path.name} already exists, skipping")
            return True
            
        # Create parent directory if it doesn't exist
        dest_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Add CivitAI token if provided and URL is from CivitAI
        download_url = url
        if civitai_token and 'civitai.com' in url:
            separator = '&' if '?' in url else '?'
            download_url = f"{url}{separator}token={civitai_token}"
        
        # Start download with streaming
        response = requests.get(download_url, stream=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        # Download with progress bar
        with open(dest_path, 'wb') as f:
            with tqdm(
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
                desc=desc or dest_path.name,
                ncols=100
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        pbar.update(len(chunk))
        
        print(f"âœ“ Downloaded {dest_path.name}")
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"âœ— Failed to download {dest_path.name}: {e}")
        # Clean up partial download
        if dest_path.exists():
            dest_path.unlink()
        return False
    except KeyboardInterrupt:
        print(f"\nâœ— Download interrupted for {dest_path.name}")
        # Clean up partial download
        if dest_path.exists():
            dest_path.unlink()
        raise
    except Exception as e:
        print(f"âœ— Unexpected error downloading {dest_path.name}: {e}")
        if dest_path.exists():
            dest_path.unlink()
        return False


def calculate_total_size(categories: List[str] = None) -> float:
    """Calculate total download size in GB."""
    total_gb = 0.0
    
    for category, files in MODELS.items():
        if categories and category not in categories:
            continue
        for file_name, file_info in files.items():
            if not (Path(file_info["path"]) / file_name).exists():
                total_gb += file_info["size_gb"]
    
    return total_gb


def download_models(
    base_path: Path,
    categories: List[str] = None,
    dry_run: bool = False,
    civitai_token: str = None
) -> Dict[str, int]:
    """
    Download all configured models.
    
    Args:
        base_path: Base path for ComfyUI installation
        categories: List of categories to download (None = all)
        dry_run: If True, only show what would be downloaded
        civitai_token: CivitAI API token for authenticated downloads
        
    Returns:
        Dictionary with success/failure counts
    """
    stats = {"success": 0, "failed": 0, "skipped": 0}
    
    # Calculate and display total size
    total_size = calculate_total_size(categories)
    if total_size > 0:
        print(f"\nğŸ“¦ Total download size: ~{total_size:.1f} GB")
        if dry_run:
            print("ğŸ” Dry run mode - no files will be downloaded\n")
        else:
            response = input("Continue? [y/N]: ")
            if response.lower() not in ['y', 'yes']:
                print("Cancelled")
                return stats
    else:
        print("\nâœ“ All files already downloaded!")
        return stats
    
    print()
    
    for category, files in MODELS.items():
        if categories and category not in categories:
            continue
            
        print(f"\n{'='*60}")
        print(f"ğŸ“‚ {category.upper()}")
        print(f"{'='*60}")
        
        for file_name, file_info in files.items():
            dest_path = base_path / file_info["path"] / file_name
            
            if dest_path.exists():
                print(f"âœ“ {file_name} already exists")
                stats["skipped"] += 1
                continue
            
            if dry_run:
                print(f"Would download: {file_name} ({file_info['size_gb']:.1f} GB)")
                print(f"  â†’ {dest_path}")
                continue
            
            print(f"\nâ¬‡ï¸  Downloading {file_name} (~{file_info['size_gb']:.1f} GB)")
            print(f"   URL: {file_info['url']}")
            print(f"   Destination: {dest_path}\n")
            
            if download_file(file_info["url"], dest_path, file_name, civitai_token):
                stats["success"] += 1
            else:
                stats["failed"] += 1
    
    return stats


def main():
    parser = argparse.ArgumentParser(
        description="Download models, LoRAs, VAEs, and encoders for ComfyUI WAN workflow"
    )
    parser.add_argument(
        "--base-path",
        type=Path,
        default=Path.cwd() / "src",
        help="Base path for ComfyUI installation (default: ./src)"
    )
    parser.add_argument(
        "--categories",
        type=str,
        nargs="+",
        choices=["clip", "vae", "diffusion_models", "unet", "loras"],
        help="Specific categories to download (default: all)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be downloaded without actually downloading"
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="List all models and exit"
    )
    parser.add_argument(
        "--civitai-token",
        type=str,
        help="CivitAI API token for downloading models from CivitAI (required for CivitAI models)"
    )
    
    args = parser.parse_args()
    
    # List mode
    if args.list:
        print("\nğŸ“‹ Available Models:\n")
        for category, files in MODELS.items():
            print(f"{category.upper()}:")
            for file_name, file_info in files.items():
                print(f"  â€¢ {file_name} ({file_info['size_gb']:.1f} GB)")
                print(f"    Path: {file_info['path']}")
                print(f"    URL: {file_info['url']}\n")
        return
    
    # Verify base path exists
    if not args.base_path.exists():
        print(f"âŒ Base path does not exist: {args.base_path}")
        print(f"   Please ensure ComfyUI is installed or specify correct --base-path")
        sys.exit(1)
    
    print("="*60)
    print("ğŸ¨ ComfyUI Model Downloader")
    print("   WAN Image-to-Video v2.2 Workflow")
    print("="*60)
    print(f"\nğŸ“ Base path: {args.base_path.absolute()}")
    
    if args.categories:
        print(f"ğŸ“¦ Categories: {', '.join(args.categories)}")
    else:
        print(f"ğŸ“¦ Categories: all")
    
    try:
        stats = download_models(
            args.base_path,
            categories=args.categories,
            dry_run=args.dry_run,
            civitai_token=args.civitai_token
        )
        
        # Print summary
        print(f"\n{'='*60}")
        print("ğŸ“Š Summary")
        print(f"{'='*60}")
        
        if args.dry_run:
            print("Dry run completed")
        else:
            print(f"âœ“ Successfully downloaded: {stats['success']}")
            print(f"âŠ˜ Skipped (already exist): {stats['skipped']}")
            if stats['failed'] > 0:
                print(f"âœ— Failed: {stats['failed']}")
                sys.exit(1)
            else:
                print(f"\nğŸ‰ All downloads completed successfully!")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Download interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
